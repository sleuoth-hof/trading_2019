\section{Vorwort}
Im heutigen hochdigitalisierten Zeitalter gewinnt der richtige Umgang mit Daten gerade auf technologischer Ebene immer mehr an Bedeutung. Nicht nur im Hinblick auf die Einhaltung der entsprechenden Datenschutzrichtlinien. Sondern gerade in Bezug auf einen nutzenorientierten, zielgerichteten und zukunftsträchtigen Gebrauch dieser Informationen, muss man sich neuen Herausforderungen stellen. Es gilt Konzepte zu entwickeln, die möglichst sinnvoll auf den verschiedenen Gebieten der Datenverarbeitung einsetzbar sind. Sie sollten sich den stetig neu ergebenden Anforderungen anpassen und umso mehr Faktoren gleichzeitig berücksichtigen können. Ein solches Konzept, welches verschiedene Bereiche des zweckmäßigen Gebrauchs von Daten auf möglichst effiziente Art und Weise vereint, ist das Data Warehouse. Dieses Prinzip bildet ein zentrales Datenbanksystem, das zu Analysezwecken verwendet wird, vgl. \cite{dtw}.
Dieses Model wird hauptsächlich im betriebswirtschaftlichen Bereich oder in der Forschung eingesetzt.  Mithilfe der richtigen Integration und Analyse von Daten können aussagekräftige, interpretierbare Ergebnisse entstehen (Wissenschaft) oder Entscheidungen entwickelt werden (Marktforschung), vgl. \cite{vorlesung}. 
Das Data Warehouse bildet hierbei eine Art Datenlager. Es bezieht Werte aus einer Reihe von verschiedenen, heterogenen Quellen, sammelt diese und legt sie in verdichteter und aufbereiteter Form in das Lager (Data Warehouse) ab. Auf diese Weise kann es die angebundenen Analysesysteme zentral mit dem ermittelten Datenkollektiv versorgen. Welche wiederum die Informationen auswerten.  Diese Gesamtheit der Prozesse zur Datenbeschaffung, Verwaltung, Sicherung und Zurverfügungstellen der Daten nennt man dementsprechend Data Warehousing, vgl. \cite{dtw}. 
Dieses beginnt mit der Auswahl geeigneter interner oder externer Quellen, die allerdings nicht zum eigentlichen digitalen Lagerhaus gehören. Hierbei muss darauf geachtet werden qualitative Datenbestände ausfindig zu machen, die für das Modell geeignet sind und die allgemein üblichen Grundanforderungen an Informationen erfüllen. Hierzu gehören unteranderem die Konsistenz, Korrektheit, und Zuverlässigkeit der verwendeten Quellen, vgl. \cite{vorlesung}. 
Die Daten werden anschließend von dem "Datenbereingungsbereich" extrahiert. Dieser stellt die zentrale Datenhaltungskomponente des Beschaffungsbereichs dar und dient als temporärer Zwischenspeicher. Hier erfolgt die Integration der Daten, welche zunächst bereinigt werden müssen, die sog. Transformation. Dies geschieht indem die fehlerhaften oder fehlenden Werte ausgebessert, Duplikate beseitigt und veraltete Werte geupdatet werden. So erfolgt die inhaltliche und durch entsprechende Schemaintegration die strukturelle Anpassung der Daten, um die Heterogenität der Quellen zu überwinden, vgl. \cite{vorlesung}.  
Nachdem die Daten dann bereinigt und in ein einheitliches Format gebracht wurden, können sie in die eigentliche Basisdatenbank geladen werden, nach Bedarf werden  Datenwürfel befüllt. Dieser Würfel ist eine besondere Datenbank, welche besser für Analysen geeignet ist, weil es aufgrund der Struktur die Daten schneller lädt. Datenwürfel und Basisdatenbank bilden hierbei dann das richtige Data Warehouse, anhand dessen die Analysen durchgeführt werden können, vgl. \cite{vorlesung}. Dabei wird nicht einfach so, sondern mithilfe von Data Marts mit den entsprechenden Access Tools zugegriffen, um die beabsichtigten Analyseverfahren durchführen zu können. So wird je nach Themengebiet eine Kennzahl gewonnen auf Basis welcher Entscheidungen oder Schlussfolgerungen getroffen werden können, vgl. \cite{dtw}.
Um dieses Prinzip des Data Warehousings an einem Beispiel umsetzen zu können, wurde im Rahmen des Wahlfachmoduls „Applied Big Data Analysis“ entschieden ein betriebswirtschaftliches Projekt anhand dieses Konzepts zu verwirklichen. In diesem Zuge entstand auch die Idee sich an den Bereich des „Tradings“ zu wenden. Wie beim üblichen Handeln mit Aktien bekannt ist, bedarf es einer ausgereiften Strategie, die aus der genauen Beobachtung der Kurse resultiert. Dementsprechend agiert man an der Börse, indem man kauft oder verkauft. Eben diesen Prozess galt es in Data Warehouse Form zu realisieren und zu digitalisieren. Als Bezugsquellen, die dem Datenlagerhaus vorangestellt sind, dienen die Datenbanken von Kryptowährungsbörsen, auf deren Inhalt über die von ihnen zur Verfügung gestellten Schnittstellen zugegriffen wird. Hierdurch werden historische Daten jeder zur analysierenden Währung extrahiert. Im selben Zusammenhang gilt es, getreu dem DWH-Prinzip, diese aufzubereiten bevor sie in das eigentliche Lagerhaus geladen werden können. Im Gegensatz zur herkömmlichen Kennzahl, wurde an dieser Stelle ein Indikator eingesetzt. Dieser dient zur Strategiefindung, indem er aus den gegeben Kursdaten Werte ermittelt anhand welcher Handlungsentscheidungen abgleitet werden. Der Indikator wird als Strategie mithilfe des Frameworks Spark implementiert. 
Apache Spark ist für Clustercomputing ausgelegt, vgl. \cite{spark}. So wird es möglich mit hoher Performance große Datenmengen aus unterschiedlichen Quellen abzufragen, was für das Data Warehouse optimal ist. Die sich durch das Gesamtanalyseverfahren ergebende Entscheidung wird von einem Bot evaluiert. Er stellt den Händler auf dem Markt dar. Ihm wird die Entscheidung weitergereicht anhand welcher er tradet, kauft oder verkauft. Dies wird genauer in den folgenden Abschnitten geschildert.
